{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884dfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from layers.dense import Dense\n",
    "from layers.conv2d import Conv2D\n",
    "from layers.ReLU import ReLU\n",
    "from layers.utils import AdamOptimizer, Sequential, compute_accuracy\n",
    "from layers.softmaxcrossentropyloss import SoftmaxCrossEntropyLoss\n",
    "from layers.maxpool2d import MaxPool2D\n",
    "from layers.flatten import Flatten\n",
    "from layers.dropout import Dropout\n",
    "from data.data_loader import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e940e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losses = {}\n",
    "all_val_losses = {}\n",
    "all_train_accuracies = {}\n",
    "all_val_accuracies = {}\n",
    "training_times = {}\n",
    "confusion_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17015b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 64, 128, 256]  # Batch sizes to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3650aadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 32] Epoch 1/50\n",
      "Loss (train): 0.3589, Acc (train): 0.8920, Loss (val): 0.2573, Acc (val): 0.9223, Epoch completed in 13.62 seconds.\n",
      "[Batch size: 32] Epoch 2/50\n",
      "Loss (train): 0.2157, Acc (train): 0.9347, Loss (val): 0.1823, Acc (val): 0.9451, Epoch completed in 11.96 seconds.\n",
      "[Batch size: 32] Epoch 3/50\n",
      "Loss (train): 0.1745, Acc (train): 0.9473, Loss (val): 0.1539, Acc (val): 0.9518, Epoch completed in 11.90 seconds.\n",
      "[Batch size: 32] Epoch 4/50\n",
      "Loss (train): 0.1513, Acc (train): 0.9539, Loss (val): 0.1371, Acc (val): 0.9565, Epoch completed in 11.96 seconds.\n",
      "[Batch size: 32] Epoch 5/50\n",
      "Loss (train): 0.1353, Acc (train): 0.9581, Loss (val): 0.1330, Acc (val): 0.9592, Epoch completed in 11.85 seconds.\n",
      "[Batch size: 32] Epoch 6/50\n",
      "Loss (train): 0.1221, Acc (train): 0.9617, Loss (val): 0.1123, Acc (val): 0.9651, Epoch completed in 12.03 seconds.\n",
      "[Batch size: 32] Epoch 7/50\n",
      "Loss (train): 0.1149, Acc (train): 0.9633, Loss (val): 0.1172, Acc (val): 0.9628, Epoch completed in 12.01 seconds.\n",
      "[Batch size: 32] Epoch 8/50\n",
      "Loss (train): 0.1113, Acc (train): 0.9650, Loss (val): 0.1238, Acc (val): 0.9590, Epoch completed in 12.05 seconds.\n",
      "[Batch size: 32] Epoch 9/50\n",
      "Loss (train): 0.1059, Acc (train): 0.9670, Loss (val): 0.1181, Acc (val): 0.9661, Epoch completed in 12.03 seconds.\n",
      "[Batch size: 32] Epoch 10/50\n",
      "Loss (train): 0.1048, Acc (train): 0.9675, Loss (val): 0.1110, Acc (val): 0.9653, Epoch completed in 12.00 seconds.\n",
      "[Batch size: 32] Epoch 11/50\n",
      "Loss (train): 0.1021, Acc (train): 0.9676, Loss (val): 0.1075, Acc (val): 0.9679, Epoch completed in 11.98 seconds.\n",
      "[Batch size: 32] Epoch 12/50\n",
      "Loss (train): 0.0993, Acc (train): 0.9683, Loss (val): 0.1123, Acc (val): 0.9650, Epoch completed in 11.91 seconds.\n",
      "[Batch size: 32] Epoch 13/50\n",
      "Loss (train): 0.0988, Acc (train): 0.9690, Loss (val): 0.1061, Acc (val): 0.9674, Epoch completed in 11.95 seconds.\n",
      "[Batch size: 32] Epoch 14/50\n",
      "Loss (train): 0.0960, Acc (train): 0.9691, Loss (val): 0.1143, Acc (val): 0.9648, Epoch completed in 11.94 seconds.\n",
      "[Batch size: 32] Epoch 15/50\n",
      "Loss (train): 0.0931, Acc (train): 0.9701, Loss (val): 0.1095, Acc (val): 0.9656, Epoch completed in 12.01 seconds.\n",
      "[Batch size: 32] Epoch 16/50\n",
      "Loss (train): 0.0930, Acc (train): 0.9711, Loss (val): 0.1115, Acc (val): 0.9651, Epoch completed in 12.03 seconds.\n",
      "[Batch size: 32] Epoch 17/50\n",
      "Loss (train): 0.0948, Acc (train): 0.9696, Loss (val): 0.1090, Acc (val): 0.9666, Epoch completed in 11.96 seconds.\n",
      "[Batch size: 32] Epoch 18/50\n",
      "Loss (train): 0.0924, Acc (train): 0.9708, Loss (val): 0.1044, Acc (val): 0.9694, Epoch completed in 11.91 seconds.\n",
      "[Batch size: 32] Epoch 19/50\n",
      "Loss (train): 0.0922, Acc (train): 0.9707, Loss (val): 0.1056, Acc (val): 0.9655, Epoch completed in 11.97 seconds.\n",
      "[Batch size: 32] Epoch 20/50\n",
      "Loss (train): 0.0912, Acc (train): 0.9710, Loss (val): 0.1073, Acc (val): 0.9674, Epoch completed in 11.97 seconds.\n",
      "[Batch size: 32] Epoch 21/50\n",
      "Loss (train): 0.0878, Acc (train): 0.9719, Loss (val): 0.1106, Acc (val): 0.9672, Epoch completed in 11.91 seconds.\n",
      "[Batch size: 32] Epoch 22/50\n",
      "Loss (train): 0.0889, Acc (train): 0.9717, Loss (val): 0.1054, Acc (val): 0.9664, Epoch completed in 12.03 seconds.\n",
      "[Batch size: 32] Epoch 23/50\n",
      "Early stopping at epoch 23.\n",
      "[Batch size: 32] Training completed in 276.98 seconds.\n",
      "Results saved: [32]custom_cnn_results.json\n",
      "[64] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 64] Epoch 1/50\n",
      "Loss (train): 0.4168, Acc (train): 0.8759, Loss (val): 0.3313, Acc (val): 0.9046, Epoch completed in 5.88 seconds.\n",
      "[Batch size: 64] Epoch 2/50\n",
      "Loss (train): 0.3211, Acc (train): 0.9048, Loss (val): 0.2501, Acc (val): 0.9293, Epoch completed in 5.90 seconds.\n",
      "[Batch size: 64] Epoch 3/50\n",
      "Loss (train): 0.2202, Acc (train): 0.9356, Loss (val): 0.1808, Acc (val): 0.9453, Epoch completed in 5.89 seconds.\n",
      "[Batch size: 64] Epoch 4/50\n",
      "Loss (train): 0.1694, Acc (train): 0.9503, Loss (val): 0.1498, Acc (val): 0.9523, Epoch completed in 5.85 seconds.\n",
      "[Batch size: 64] Epoch 5/50\n",
      "Loss (train): 0.1479, Acc (train): 0.9552, Loss (val): 0.1363, Acc (val): 0.9568, Epoch completed in 5.89 seconds.\n",
      "[Batch size: 64] Epoch 6/50\n",
      "Loss (train): 0.1341, Acc (train): 0.9589, Loss (val): 0.1321, Acc (val): 0.9627, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 7/50\n",
      "Loss (train): 0.1243, Acc (train): 0.9612, Loss (val): 0.1186, Acc (val): 0.9629, Epoch completed in 5.84 seconds.\n",
      "[Batch size: 64] Epoch 8/50\n",
      "Loss (train): 0.1178, Acc (train): 0.9638, Loss (val): 0.1145, Acc (val): 0.9652, Epoch completed in 5.88 seconds.\n",
      "[Batch size: 64] Epoch 9/50\n",
      "Loss (train): 0.1101, Acc (train): 0.9654, Loss (val): 0.1075, Acc (val): 0.9674, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 10/50\n",
      "Loss (train): 0.1060, Acc (train): 0.9678, Loss (val): 0.1077, Acc (val): 0.9661, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 11/50\n",
      "Loss (train): 0.1027, Acc (train): 0.9678, Loss (val): 0.1088, Acc (val): 0.9662, Epoch completed in 5.88 seconds.\n",
      "[Batch size: 64] Epoch 12/50\n",
      "Loss (train): 0.0982, Acc (train): 0.9690, Loss (val): 0.1064, Acc (val): 0.9681, Epoch completed in 5.90 seconds.\n",
      "[Batch size: 64] Epoch 13/50\n",
      "Loss (train): 0.0952, Acc (train): 0.9700, Loss (val): 0.1085, Acc (val): 0.9665, Epoch completed in 5.89 seconds.\n",
      "[Batch size: 64] Epoch 14/50\n",
      "Loss (train): 0.0930, Acc (train): 0.9700, Loss (val): 0.1052, Acc (val): 0.9662, Epoch completed in 5.87 seconds.\n",
      "[Batch size: 64] Epoch 15/50\n",
      "Loss (train): 0.0934, Acc (train): 0.9707, Loss (val): 0.1058, Acc (val): 0.9663, Epoch completed in 5.88 seconds.\n",
      "[Batch size: 64] Epoch 16/50\n",
      "Loss (train): 0.0899, Acc (train): 0.9714, Loss (val): 0.1099, Acc (val): 0.9681, Epoch completed in 5.87 seconds.\n",
      "[Batch size: 64] Epoch 17/50\n",
      "Loss (train): 0.0882, Acc (train): 0.9716, Loss (val): 0.1004, Acc (val): 0.9686, Epoch completed in 5.85 seconds.\n",
      "[Batch size: 64] Epoch 18/50\n",
      "Loss (train): 0.0885, Acc (train): 0.9719, Loss (val): 0.1080, Acc (val): 0.9670, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 19/50\n",
      "Loss (train): 0.0834, Acc (train): 0.9733, Loss (val): 0.1103, Acc (val): 0.9652, Epoch completed in 5.85 seconds.\n",
      "[Batch size: 64] Epoch 20/50\n",
      "Loss (train): 0.0827, Acc (train): 0.9735, Loss (val): 0.1046, Acc (val): 0.9685, Epoch completed in 5.85 seconds.\n",
      "[Batch size: 64] Epoch 21/50\n",
      "Loss (train): 0.0844, Acc (train): 0.9729, Loss (val): 0.0984, Acc (val): 0.9688, Epoch completed in 5.88 seconds.\n",
      "[Batch size: 64] Epoch 22/50\n",
      "Loss (train): 0.0841, Acc (train): 0.9728, Loss (val): 0.0980, Acc (val): 0.9718, Epoch completed in 5.85 seconds.\n",
      "[Batch size: 64] Epoch 23/50\n",
      "Loss (train): 0.0833, Acc (train): 0.9734, Loss (val): 0.1069, Acc (val): 0.9656, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 24/50\n",
      "Loss (train): 0.0836, Acc (train): 0.9723, Loss (val): 0.1071, Acc (val): 0.9660, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 25/50\n",
      "Loss (train): 0.0812, Acc (train): 0.9737, Loss (val): 0.0935, Acc (val): 0.9707, Epoch completed in 5.87 seconds.\n",
      "[Batch size: 64] Epoch 26/50\n",
      "Loss (train): 0.0805, Acc (train): 0.9734, Loss (val): 0.0981, Acc (val): 0.9708, Epoch completed in 5.84 seconds.\n",
      "[Batch size: 64] Epoch 27/50\n",
      "Loss (train): 0.0809, Acc (train): 0.9738, Loss (val): 0.1060, Acc (val): 0.9673, Epoch completed in 5.86 seconds.\n",
      "[Batch size: 64] Epoch 28/50\n",
      "Loss (train): 0.0800, Acc (train): 0.9746, Loss (val): 0.1066, Acc (val): 0.9670, Epoch completed in 5.87 seconds.\n",
      "[Batch size: 64] Epoch 29/50\n",
      "Loss (train): 0.0782, Acc (train): 0.9744, Loss (val): 0.1024, Acc (val): 0.9706, Epoch completed in 5.83 seconds.\n",
      "[Batch size: 64] Epoch 30/50\n",
      "Early stopping at epoch 30.\n",
      "[Batch size: 64] Training completed in 175.97 seconds.\n",
      "Results saved: [64]custom_cnn_results.json\n",
      "[128] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 128] Epoch 1/50\n",
      "Loss (train): 0.4664, Acc (train): 0.8608, Loss (val): 0.3536, Acc (val): 0.8957, Epoch completed in 4.05 seconds.\n",
      "[Batch size: 128] Epoch 2/50\n",
      "Loss (train): 0.3556, Acc (train): 0.8957, Loss (val): 0.3309, Acc (val): 0.9047, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 3/50\n",
      "Loss (train): 0.3408, Acc (train): 0.8990, Loss (val): 0.3182, Acc (val): 0.9101, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 4/50\n",
      "Loss (train): 0.2992, Acc (train): 0.9115, Loss (val): 0.2543, Acc (val): 0.9304, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 5/50\n",
      "Loss (train): 0.2280, Acc (train): 0.9336, Loss (val): 0.1931, Acc (val): 0.9452, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 6/50\n",
      "Loss (train): 0.1891, Acc (train): 0.9433, Loss (val): 0.1709, Acc (val): 0.9484, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 7/50\n",
      "Loss (train): 0.1737, Acc (train): 0.9480, Loss (val): 0.1637, Acc (val): 0.9508, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 8/50\n",
      "Loss (train): 0.1636, Acc (train): 0.9511, Loss (val): 0.1591, Acc (val): 0.9524, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 9/50\n",
      "Loss (train): 0.1575, Acc (train): 0.9516, Loss (val): 0.1533, Acc (val): 0.9518, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 10/50\n",
      "Loss (train): 0.1521, Acc (train): 0.9533, Loss (val): 0.1500, Acc (val): 0.9551, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 11/50\n",
      "Loss (train): 0.1495, Acc (train): 0.9537, Loss (val): 0.1516, Acc (val): 0.9534, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 12/50\n",
      "Loss (train): 0.1462, Acc (train): 0.9545, Loss (val): 0.1470, Acc (val): 0.9533, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 13/50\n",
      "Loss (train): 0.1417, Acc (train): 0.9560, Loss (val): 0.1404, Acc (val): 0.9552, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 14/50\n",
      "Loss (train): 0.1399, Acc (train): 0.9570, Loss (val): 0.1468, Acc (val): 0.9543, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 15/50\n",
      "Loss (train): 0.1391, Acc (train): 0.9574, Loss (val): 0.1433, Acc (val): 0.9579, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 16/50\n",
      "Loss (train): 0.1331, Acc (train): 0.9589, Loss (val): 0.1378, Acc (val): 0.9565, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 17/50\n",
      "Loss (train): 0.1322, Acc (train): 0.9587, Loss (val): 0.1355, Acc (val): 0.9578, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 18/50\n",
      "Loss (train): 0.1292, Acc (train): 0.9595, Loss (val): 0.1295, Acc (val): 0.9616, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 19/50\n",
      "Loss (train): 0.1285, Acc (train): 0.9600, Loss (val): 0.1311, Acc (val): 0.9600, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 20/50\n",
      "Loss (train): 0.1236, Acc (train): 0.9618, Loss (val): 0.1321, Acc (val): 0.9597, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 21/50\n",
      "Loss (train): 0.1204, Acc (train): 0.9618, Loss (val): 0.1331, Acc (val): 0.9588, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 22/50\n",
      "Loss (train): 0.1165, Acc (train): 0.9636, Loss (val): 0.1248, Acc (val): 0.9615, Epoch completed in 4.05 seconds.\n",
      "[Batch size: 128] Epoch 23/50\n",
      "Loss (train): 0.1186, Acc (train): 0.9634, Loss (val): 0.1276, Acc (val): 0.9612, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 24/50\n",
      "Loss (train): 0.1131, Acc (train): 0.9636, Loss (val): 0.1263, Acc (val): 0.9594, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 25/50\n",
      "Loss (train): 0.1093, Acc (train): 0.9648, Loss (val): 0.1204, Acc (val): 0.9629, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 26/50\n",
      "Loss (train): 0.1121, Acc (train): 0.9645, Loss (val): 0.1275, Acc (val): 0.9595, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 27/50\n",
      "Loss (train): 0.1102, Acc (train): 0.9651, Loss (val): 0.1231, Acc (val): 0.9627, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 28/50\n",
      "Loss (train): 0.1084, Acc (train): 0.9657, Loss (val): 0.1232, Acc (val): 0.9615, Epoch completed in 4.04 seconds.\n",
      "[Batch size: 128] Epoch 29/50\n",
      "Loss (train): 0.1109, Acc (train): 0.9648, Loss (val): 0.1167, Acc (val): 0.9651, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 30/50\n",
      "Loss (train): 0.1072, Acc (train): 0.9649, Loss (val): 0.1234, Acc (val): 0.9627, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 31/50\n",
      "Loss (train): 0.1089, Acc (train): 0.9661, Loss (val): 0.1243, Acc (val): 0.9624, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 32/50\n",
      "Loss (train): 0.1056, Acc (train): 0.9661, Loss (val): 0.1194, Acc (val): 0.9627, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 33/50\n",
      "Loss (train): 0.1048, Acc (train): 0.9657, Loss (val): 0.1213, Acc (val): 0.9632, Epoch completed in 4.03 seconds.\n",
      "[Batch size: 128] Epoch 34/50\n",
      "Early stopping at epoch 34.\n",
      "[Batch size: 128] Training completed in 137.23 seconds.\n",
      "Results saved: [128]custom_cnn_results.json\n",
      "[256] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 256] Epoch 1/50\n",
      "Loss (train): 0.5172, Acc (train): 0.8526, Loss (val): 0.3345, Acc (val): 0.8979, Epoch completed in 6.43 seconds.\n",
      "[Batch size: 256] Epoch 2/50\n",
      "Loss (train): 0.3515, Acc (train): 0.8949, Loss (val): 0.3248, Acc (val): 0.9051, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 3/50\n",
      "Loss (train): 0.3403, Acc (train): 0.8992, Loss (val): 0.3264, Acc (val): 0.9053, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 4/50\n",
      "Loss (train): 0.3321, Acc (train): 0.9015, Loss (val): 0.3184, Acc (val): 0.9058, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 5/50\n",
      "Loss (train): 0.3204, Acc (train): 0.9045, Loss (val): 0.3024, Acc (val): 0.9120, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 6/50\n",
      "Loss (train): 0.2805, Acc (train): 0.9166, Loss (val): 0.2494, Acc (val): 0.9290, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 7/50\n",
      "Loss (train): 0.2257, Acc (train): 0.9332, Loss (val): 0.1992, Acc (val): 0.9447, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 8/50\n",
      "Loss (train): 0.1908, Acc (train): 0.9443, Loss (val): 0.1746, Acc (val): 0.9496, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 9/50\n",
      "Loss (train): 0.1715, Acc (train): 0.9483, Loss (val): 0.1629, Acc (val): 0.9516, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 10/50\n",
      "Loss (train): 0.1622, Acc (train): 0.9511, Loss (val): 0.1520, Acc (val): 0.9553, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 11/50\n",
      "Loss (train): 0.1530, Acc (train): 0.9541, Loss (val): 0.1504, Acc (val): 0.9550, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 12/50\n",
      "Loss (train): 0.1471, Acc (train): 0.9551, Loss (val): 0.1453, Acc (val): 0.9551, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 13/50\n",
      "Loss (train): 0.1407, Acc (train): 0.9573, Loss (val): 0.1391, Acc (val): 0.9588, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 14/50\n",
      "Loss (train): 0.1369, Acc (train): 0.9579, Loss (val): 0.1502, Acc (val): 0.9548, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 15/50\n",
      "Loss (train): 0.1336, Acc (train): 0.9586, Loss (val): 0.1367, Acc (val): 0.9580, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 16/50\n",
      "Loss (train): 0.1297, Acc (train): 0.9601, Loss (val): 0.1342, Acc (val): 0.9599, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 17/50\n",
      "Loss (train): 0.1266, Acc (train): 0.9613, Loss (val): 0.1280, Acc (val): 0.9592, Epoch completed in 3.67 seconds.\n",
      "[Batch size: 256] Epoch 18/50\n",
      "Loss (train): 0.1253, Acc (train): 0.9604, Loss (val): 0.1280, Acc (val): 0.9604, Epoch completed in 3.65 seconds.\n",
      "[Batch size: 256] Epoch 19/50\n",
      "Loss (train): 0.1207, Acc (train): 0.9623, Loss (val): 0.1348, Acc (val): 0.9578, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 20/50\n",
      "Loss (train): 0.1190, Acc (train): 0.9630, Loss (val): 0.1372, Acc (val): 0.9584, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 21/50\n",
      "Loss (train): 0.1186, Acc (train): 0.9621, Loss (val): 0.1252, Acc (val): 0.9596, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 22/50\n",
      "Loss (train): 0.1156, Acc (train): 0.9638, Loss (val): 0.1269, Acc (val): 0.9602, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 23/50\n",
      "Loss (train): 0.1146, Acc (train): 0.9643, Loss (val): 0.1212, Acc (val): 0.9624, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 24/50\n",
      "Loss (train): 0.1130, Acc (train): 0.9649, Loss (val): 0.1223, Acc (val): 0.9615, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 25/50\n",
      "Loss (train): 0.1120, Acc (train): 0.9649, Loss (val): 0.1204, Acc (val): 0.9610, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 26/50\n",
      "Loss (train): 0.1120, Acc (train): 0.9648, Loss (val): 0.1224, Acc (val): 0.9621, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 27/50\n",
      "Loss (train): 0.1094, Acc (train): 0.9654, Loss (val): 0.1211, Acc (val): 0.9651, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 28/50\n",
      "Loss (train): 0.1058, Acc (train): 0.9665, Loss (val): 0.1154, Acc (val): 0.9643, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 29/50\n",
      "Loss (train): 0.1066, Acc (train): 0.9666, Loss (val): 0.1156, Acc (val): 0.9612, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 30/50\n",
      "Loss (train): 0.1059, Acc (train): 0.9668, Loss (val): 0.1275, Acc (val): 0.9615, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 31/50\n",
      "Loss (train): 0.1050, Acc (train): 0.9670, Loss (val): 0.1147, Acc (val): 0.9639, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 32/50\n",
      "Loss (train): 0.1021, Acc (train): 0.9674, Loss (val): 0.1202, Acc (val): 0.9626, Epoch completed in 3.65 seconds.\n",
      "[Batch size: 256] Epoch 33/50\n",
      "Loss (train): 0.1022, Acc (train): 0.9675, Loss (val): 0.1187, Acc (val): 0.9645, Epoch completed in 3.65 seconds.\n",
      "[Batch size: 256] Epoch 34/50\n",
      "Loss (train): 0.1016, Acc (train): 0.9681, Loss (val): 0.1173, Acc (val): 0.9653, Epoch completed in 3.65 seconds.\n",
      "[Batch size: 256] Epoch 35/50\n",
      "Loss (train): 0.1018, Acc (train): 0.9671, Loss (val): 0.1224, Acc (val): 0.9611, Epoch completed in 3.66 seconds.\n",
      "[Batch size: 256] Epoch 36/50\n",
      "Early stopping at epoch 36.\n",
      "[Batch size: 256] Training completed in 134.57 seconds.\n",
      "Results saved: [256]custom_cnn_results.json\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    # load data\n",
    "    print(f\"[{batch_size}] Loading data...\")\n",
    "    train_loader = Data(\n",
    "        path=\"D:/studia/SieciNeuronowe/dataset/train\",\n",
    "        batch_size=batch_size,\n",
    "        use_cupy=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = Data(\n",
    "        path=\"D:/studia/SieciNeuronowe/dataset/test\",\n",
    "        batch_size=batch_size,\n",
    "        use_cupy=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # MODEL\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(\n",
    "                input_channels=1, output_channels=8, kernel_size=2, stride=1, padding=1\n",
    "            ),\n",
    "            ReLU(),\n",
    "            MaxPool2D(kernel_size=2, stride=2),\n",
    "            Dropout(0.3),  # Dropout layer with 40% dropout rate\n",
    "            Flatten(),\n",
    "            Dense(input_size=8 * 14 * 14, output_size=10),\n",
    "        ]\n",
    "    )\n",
    "    loss_fn = SoftmaxCrossEntropyLoss()\n",
    "    optimizer = AdamOptimizer(learning_rate=0.005)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    epochs_done_all = {}\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    epochs_done = 0\n",
    "    num_epochs = 50\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"[Batch size: {batch_size}] Epoch {epoch + 1}/{num_epochs}\")\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            logits = model.forward(x_batch)\n",
    "            loss = loss_fn.forward(logits, y_batch)\n",
    "            grad = loss_fn.backward()\n",
    "            model.backward(grad)\n",
    "            model.update(optimizer)\n",
    "\n",
    "            train_loss += float(loss)\n",
    "            train_acc += float(compute_accuracy(logits, y_batch))\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss /= num_batches\n",
    "        train_acc /= num_batches\n",
    "\n",
    "        val_logits = model.forward(val_loader.X)\n",
    "        val_loss = loss_fn.forward(val_logits, val_loader.y)\n",
    "        val_acc = compute_accuracy(val_logits, val_loader.y)\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}.\")\n",
    "                break\n",
    "        print(\n",
    "            f\"Loss (train): {train_loss:.4f}, Acc (train): {train_acc:.4f}, \"\n",
    "            f\"Loss (val): {float(val_loss):.4f}, Acc (val): {float(val_acc):.4f}, \"\n",
    "            f\"Epoch completed in {time.time() - epoch_start_time:.2f} seconds.\"\n",
    "        )\n",
    "        epochs_done += 1\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(float(val_loss))\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(float(val_acc))\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"[Batch size: {batch_size}] Training completed in {time.time() - start_time:.2f} seconds.\"\n",
    "    )\n",
    "    \n",
    "    training_time = end_time - start_time\n",
    "    epochs_done_all[batch_size] = epochs_done\n",
    "    training_times[batch_size] = training_time\n",
    "    all_train_losses[batch_size] = train_losses\n",
    "    all_val_losses[batch_size] = val_losses\n",
    "    all_train_accuracies[batch_size] = train_accuracies\n",
    "    all_val_accuracies[batch_size] = val_accuracies\n",
    "    true_labels = val_loader.y.get()\n",
    "    val_logits = model.forward(val_loader.X)\n",
    "    val_preds = np.argmax(val_logits.get(), axis=1)\n",
    "\n",
    "    cm = confusion_matrix(true_labels, val_preds)\n",
    "    confusion_matrices[batch_size] = cm\n",
    "    results = {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"train_accuracy\": train_accuracies,\n",
    "        \"val_accuracy\": val_accuracies,\n",
    "        \"training_time_seconds\": training_time,\n",
    "        \"confusion_matrix\": cm.tolist(),  # Convert to list for JSON serialization\n",
    "        \"epochs_done\": epochs_done,\n",
    "    }\n",
    "\n",
    "    # Save results to JSON file\n",
    "    with open(f\"../DOCS/[{batch_size}]custom_cnn_results.json\", \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    print(f\"Results saved: [{batch_size}]custom_cnn_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

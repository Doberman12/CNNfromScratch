{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884dfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from layers.dense import Dense\n",
    "from layers.conv2d import Conv2D\n",
    "from layers.ReLU import ReLU\n",
    "from layers.utils import im2col, col2im, AdamOptimizer, Sequential, compute_accuracy\n",
    "from layers.softmaxcrossentropyloss import SoftmaxCrossEntropyLoss\n",
    "from layers.maxpool2d import MaxPool2D\n",
    "from layers.flatten import Flatten\n",
    "from layers.dropout import Dropout\n",
    "from data.data_loader import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e940e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losses = {}\n",
    "all_val_losses = {}\n",
    "all_train_accuracies = {}\n",
    "all_val_accuracies = {}\n",
    "training_times = {}\n",
    "confusion_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17015b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 64, 128, 256]  # Batch sizes to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650aadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 32] Epoch 1/50\n",
      "Loss (train): 1.0837, Acc (train): 0.8051, Loss (val): 0.6310, Acc (val): 0.8659, Epoch completed in 6.39 seconds.\n",
      "[Batch size: 32] Epoch 2/50\n",
      "Loss (train): 0.5491, Acc (train): 0.8687, Loss (val): 0.4654, Acc (val): 0.8877, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 3/50\n",
      "Loss (train): 0.4471, Acc (train): 0.8833, Loss (val): 0.4040, Acc (val): 0.8943, Epoch completed in 5.99 seconds.\n",
      "[Batch size: 32] Epoch 4/50\n",
      "Loss (train): 0.3987, Acc (train): 0.8916, Loss (val): 0.3692, Acc (val): 0.8987, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 5/50\n",
      "Loss (train): 0.3705, Acc (train): 0.8980, Loss (val): 0.3452, Acc (val): 0.9060, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 32] Epoch 6/50\n",
      "Loss (train): 0.3502, Acc (train): 0.9004, Loss (val): 0.3273, Acc (val): 0.9084, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 32] Epoch 7/50\n",
      "Loss (train): 0.3369, Acc (train): 0.9032, Loss (val): 0.3180, Acc (val): 0.9103, Epoch completed in 6.05 seconds.\n",
      "[Batch size: 32] Epoch 8/50\n",
      "Loss (train): 0.3240, Acc (train): 0.9070, Loss (val): 0.3060, Acc (val): 0.9150, Epoch completed in 6.03 seconds.\n",
      "[Batch size: 32] Epoch 9/50\n",
      "Loss (train): 0.3150, Acc (train): 0.9089, Loss (val): 0.3018, Acc (val): 0.9141, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 32] Epoch 10/50\n",
      "Loss (train): 0.3072, Acc (train): 0.9113, Loss (val): 0.2940, Acc (val): 0.9160, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 11/50\n",
      "Loss (train): 0.3006, Acc (train): 0.9126, Loss (val): 0.2879, Acc (val): 0.9199, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 32] Epoch 12/50\n",
      "Loss (train): 0.2936, Acc (train): 0.9156, Loss (val): 0.2828, Acc (val): 0.9201, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 32] Epoch 13/50\n",
      "Loss (train): 0.2889, Acc (train): 0.9148, Loss (val): 0.2745, Acc (val): 0.9217, Epoch completed in 6.33 seconds.\n",
      "[Batch size: 32] Epoch 14/50\n",
      "Loss (train): 0.2841, Acc (train): 0.9175, Loss (val): 0.2763, Acc (val): 0.9215, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 32] Epoch 15/50\n",
      "Loss (train): 0.2801, Acc (train): 0.9197, Loss (val): 0.2701, Acc (val): 0.9268, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 16/50\n",
      "Loss (train): 0.2762, Acc (train): 0.9201, Loss (val): 0.2672, Acc (val): 0.9252, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 17/50\n",
      "Loss (train): 0.2714, Acc (train): 0.9206, Loss (val): 0.2627, Acc (val): 0.9236, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 18/50\n",
      "Loss (train): 0.2701, Acc (train): 0.9217, Loss (val): 0.2638, Acc (val): 0.9211, Epoch completed in 6.02 seconds.\n",
      "[Batch size: 32] Epoch 19/50\n",
      "Loss (train): 0.2637, Acc (train): 0.9232, Loss (val): 0.2607, Acc (val): 0.9238, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 32] Epoch 20/50\n",
      "Loss (train): 0.2635, Acc (train): 0.9240, Loss (val): 0.2546, Acc (val): 0.9277, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 32] Epoch 21/50\n",
      "Loss (train): 0.2602, Acc (train): 0.9253, Loss (val): 0.2543, Acc (val): 0.9277, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 22/50\n",
      "Loss (train): 0.2583, Acc (train): 0.9244, Loss (val): 0.2524, Acc (val): 0.9281, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 23/50\n",
      "Loss (train): 0.2547, Acc (train): 0.9258, Loss (val): 0.2480, Acc (val): 0.9305, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 32] Epoch 24/50\n",
      "Loss (train): 0.2530, Acc (train): 0.9255, Loss (val): 0.2482, Acc (val): 0.9303, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 32] Epoch 25/50\n",
      "Loss (train): 0.2517, Acc (train): 0.9267, Loss (val): 0.2481, Acc (val): 0.9289, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 32] Epoch 26/50\n",
      "Loss (train): 0.2492, Acc (train): 0.9273, Loss (val): 0.2447, Acc (val): 0.9292, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 32] Epoch 27/50\n",
      "Loss (train): 0.2464, Acc (train): 0.9280, Loss (val): 0.2423, Acc (val): 0.9302, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 32] Epoch 28/50\n",
      "Loss (train): 0.2449, Acc (train): 0.9283, Loss (val): 0.2411, Acc (val): 0.9310, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 29/50\n",
      "Loss (train): 0.2440, Acc (train): 0.9286, Loss (val): 0.2433, Acc (val): 0.9317, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 32] Epoch 30/50\n",
      "Loss (train): 0.2433, Acc (train): 0.9293, Loss (val): 0.2410, Acc (val): 0.9335, Epoch completed in 6.03 seconds.\n",
      "[Batch size: 32] Epoch 31/50\n",
      "Loss (train): 0.2427, Acc (train): 0.9288, Loss (val): 0.2424, Acc (val): 0.9294, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 32] Epoch 32/50\n",
      "Loss (train): 0.2393, Acc (train): 0.9297, Loss (val): 0.2417, Acc (val): 0.9307, Epoch completed in 6.04 seconds.\n",
      "[Batch size: 32] Epoch 33/50\n",
      "Loss (train): 0.2385, Acc (train): 0.9297, Loss (val): 0.2393, Acc (val): 0.9290, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 32] Epoch 34/50\n",
      "Loss (train): 0.2373, Acc (train): 0.9295, Loss (val): 0.2356, Acc (val): 0.9312, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 35/50\n",
      "Loss (train): 0.2357, Acc (train): 0.9308, Loss (val): 0.2414, Acc (val): 0.9318, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 32] Epoch 36/50\n",
      "Loss (train): 0.2338, Acc (train): 0.9321, Loss (val): 0.2298, Acc (val): 0.9339, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 32] Epoch 37/50\n",
      "Loss (train): 0.2329, Acc (train): 0.9327, Loss (val): 0.2298, Acc (val): 0.9351, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 38/50\n",
      "Loss (train): 0.2318, Acc (train): 0.9325, Loss (val): 0.2256, Acc (val): 0.9339, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 32] Epoch 39/50\n",
      "Loss (train): 0.2293, Acc (train): 0.9330, Loss (val): 0.2309, Acc (val): 0.9325, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 32] Epoch 40/50\n",
      "Loss (train): 0.2302, Acc (train): 0.9325, Loss (val): 0.2320, Acc (val): 0.9341, Epoch completed in 6.04 seconds.\n",
      "[Batch size: 32] Epoch 41/50\n",
      "Loss (train): 0.2279, Acc (train): 0.9330, Loss (val): 0.2283, Acc (val): 0.9321, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 32] Epoch 42/50\n",
      "Loss (train): 0.2285, Acc (train): 0.9320, Loss (val): 0.2328, Acc (val): 0.9314, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 32] Epoch 43/50\n",
      "Early stopping at epoch 43.\n",
      "[Batch size: 32] Training completed in 262.43 seconds.\n",
      "Wyniki zapisane do [32]custom_cnn_results.json\n",
      "[64] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 64] Epoch 1/50\n",
      "Loss (train): 1.5781, Acc (train): 0.7574, Loss (val): 1.1024, Acc (val): 0.8360, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 64] Epoch 2/50\n",
      "Loss (train): 0.9191, Acc (train): 0.8368, Loss (val): 0.7649, Acc (val): 0.8582, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 64] Epoch 3/50\n",
      "Loss (train): 0.6963, Acc (train): 0.8564, Loss (val): 0.6164, Acc (val): 0.8724, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 64] Epoch 4/50\n",
      "Loss (train): 0.5834, Acc (train): 0.8700, Loss (val): 0.5283, Acc (val): 0.8865, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 64] Epoch 5/50\n",
      "Loss (train): 0.5136, Acc (train): 0.8793, Loss (val): 0.4731, Acc (val): 0.8887, Epoch completed in 6.27 seconds.\n",
      "[Batch size: 64] Epoch 6/50\n",
      "Loss (train): 0.4674, Acc (train): 0.8837, Loss (val): 0.4369, Acc (val): 0.8940, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 64] Epoch 7/50\n",
      "Loss (train): 0.4349, Acc (train): 0.8896, Loss (val): 0.4100, Acc (val): 0.9013, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 64] Epoch 8/50\n",
      "Loss (train): 0.4114, Acc (train): 0.8922, Loss (val): 0.3876, Acc (val): 0.9017, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 64] Epoch 9/50\n",
      "Loss (train): 0.3914, Acc (train): 0.8965, Loss (val): 0.3708, Acc (val): 0.9060, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 64] Epoch 10/50\n",
      "Loss (train): 0.3762, Acc (train): 0.8997, Loss (val): 0.3624, Acc (val): 0.9056, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 64] Epoch 11/50\n",
      "Loss (train): 0.3630, Acc (train): 0.9011, Loss (val): 0.3492, Acc (val): 0.9101, Epoch completed in 6.65 seconds.\n",
      "[Batch size: 64] Epoch 12/50\n",
      "Loss (train): 0.3533, Acc (train): 0.9036, Loss (val): 0.3338, Acc (val): 0.9120, Epoch completed in 6.29 seconds.\n",
      "[Batch size: 64] Epoch 13/50\n",
      "Loss (train): 0.3415, Acc (train): 0.9060, Loss (val): 0.3299, Acc (val): 0.9113, Epoch completed in 6.25 seconds.\n",
      "[Batch size: 64] Epoch 14/50\n",
      "Loss (train): 0.3342, Acc (train): 0.9076, Loss (val): 0.3182, Acc (val): 0.9141, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 64] Epoch 15/50\n",
      "Loss (train): 0.3284, Acc (train): 0.9086, Loss (val): 0.3162, Acc (val): 0.9148, Epoch completed in 6.28 seconds.\n",
      "[Batch size: 64] Epoch 16/50\n",
      "Loss (train): 0.3208, Acc (train): 0.9114, Loss (val): 0.3129, Acc (val): 0.9166, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 64] Epoch 17/50\n",
      "Loss (train): 0.3163, Acc (train): 0.9102, Loss (val): 0.3045, Acc (val): 0.9183, Epoch completed in 6.24 seconds.\n",
      "[Batch size: 64] Epoch 18/50\n",
      "Loss (train): 0.3094, Acc (train): 0.9128, Loss (val): 0.2971, Acc (val): 0.9196, Epoch completed in 6.41 seconds.\n",
      "[Batch size: 64] Epoch 19/50\n",
      "Loss (train): 0.3044, Acc (train): 0.9138, Loss (val): 0.2943, Acc (val): 0.9203, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 64] Epoch 20/50\n",
      "Loss (train): 0.3015, Acc (train): 0.9140, Loss (val): 0.2857, Acc (val): 0.9209, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 64] Epoch 21/50\n",
      "Loss (train): 0.2957, Acc (train): 0.9160, Loss (val): 0.2874, Acc (val): 0.9209, Epoch completed in 6.25 seconds.\n",
      "[Batch size: 64] Epoch 22/50\n",
      "Loss (train): 0.2905, Acc (train): 0.9176, Loss (val): 0.2823, Acc (val): 0.9227, Epoch completed in 6.30 seconds.\n",
      "[Batch size: 64] Epoch 23/50\n",
      "Loss (train): 0.2878, Acc (train): 0.9186, Loss (val): 0.2804, Acc (val): 0.9211, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 64] Epoch 24/50\n",
      "Loss (train): 0.2853, Acc (train): 0.9188, Loss (val): 0.2779, Acc (val): 0.9225, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 64] Epoch 25/50\n",
      "Loss (train): 0.2819, Acc (train): 0.9197, Loss (val): 0.2734, Acc (val): 0.9237, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 64] Epoch 26/50\n",
      "Loss (train): 0.2783, Acc (train): 0.9201, Loss (val): 0.2739, Acc (val): 0.9215, Epoch completed in 6.26 seconds.\n",
      "[Batch size: 64] Epoch 27/50\n",
      "Loss (train): 0.2769, Acc (train): 0.9202, Loss (val): 0.2715, Acc (val): 0.9234, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 64] Epoch 28/50\n",
      "Loss (train): 0.2736, Acc (train): 0.9221, Loss (val): 0.2646, Acc (val): 0.9270, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 64] Epoch 29/50\n",
      "Loss (train): 0.2701, Acc (train): 0.9230, Loss (val): 0.2594, Acc (val): 0.9291, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 64] Epoch 30/50\n",
      "Loss (train): 0.2668, Acc (train): 0.9245, Loss (val): 0.2601, Acc (val): 0.9262, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 64] Epoch 31/50\n",
      "Loss (train): 0.2652, Acc (train): 0.9245, Loss (val): 0.2620, Acc (val): 0.9257, Epoch completed in 6.27 seconds.\n",
      "[Batch size: 64] Epoch 32/50\n",
      "Loss (train): 0.2632, Acc (train): 0.9251, Loss (val): 0.2542, Acc (val): 0.9309, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 64] Epoch 33/50\n",
      "Loss (train): 0.2609, Acc (train): 0.9246, Loss (val): 0.2515, Acc (val): 0.9308, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 64] Epoch 34/50\n",
      "Loss (train): 0.2584, Acc (train): 0.9252, Loss (val): 0.2562, Acc (val): 0.9286, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 64] Epoch 35/50\n",
      "Loss (train): 0.2571, Acc (train): 0.9259, Loss (val): 0.2556, Acc (val): 0.9285, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 64] Epoch 36/50\n",
      "Loss (train): 0.2545, Acc (train): 0.9266, Loss (val): 0.2520, Acc (val): 0.9318, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 64] Epoch 37/50\n",
      "Loss (train): 0.2551, Acc (train): 0.9261, Loss (val): 0.2471, Acc (val): 0.9297, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 64] Epoch 38/50\n",
      "Loss (train): 0.2506, Acc (train): 0.9277, Loss (val): 0.2486, Acc (val): 0.9319, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 64] Epoch 39/50\n",
      "Loss (train): 0.2509, Acc (train): 0.9271, Loss (val): 0.2432, Acc (val): 0.9324, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 64] Epoch 40/50\n",
      "Loss (train): 0.2478, Acc (train): 0.9282, Loss (val): 0.2458, Acc (val): 0.9297, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 64] Epoch 41/50\n",
      "Loss (train): 0.2473, Acc (train): 0.9295, Loss (val): 0.2424, Acc (val): 0.9320, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 64] Epoch 42/50\n",
      "Loss (train): 0.2457, Acc (train): 0.9292, Loss (val): 0.2410, Acc (val): 0.9324, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 64] Epoch 43/50\n",
      "Loss (train): 0.2467, Acc (train): 0.9285, Loss (val): 0.2394, Acc (val): 0.9310, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 64] Epoch 44/50\n",
      "Loss (train): 0.2431, Acc (train): 0.9307, Loss (val): 0.2387, Acc (val): 0.9312, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 64] Epoch 45/50\n",
      "Loss (train): 0.2430, Acc (train): 0.9290, Loss (val): 0.2390, Acc (val): 0.9330, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 64] Epoch 46/50\n",
      "Loss (train): 0.2394, Acc (train): 0.9308, Loss (val): 0.2369, Acc (val): 0.9347, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 64] Epoch 47/50\n",
      "Loss (train): 0.2384, Acc (train): 0.9320, Loss (val): 0.2340, Acc (val): 0.9328, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 64] Epoch 48/50\n",
      "Loss (train): 0.2366, Acc (train): 0.9321, Loss (val): 0.2342, Acc (val): 0.9353, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 64] Epoch 49/50\n",
      "Loss (train): 0.2371, Acc (train): 0.9319, Loss (val): 0.2340, Acc (val): 0.9323, Epoch completed in 6.25 seconds.\n",
      "[Batch size: 64] Epoch 50/50\n",
      "Loss (train): 0.2350, Acc (train): 0.9329, Loss (val): 0.2317, Acc (val): 0.9348, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 64] Training completed in 309.43 seconds.\n",
      "Wyniki zapisane do [64]custom_cnn_results.json\n",
      "[128] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 128] Epoch 1/50\n",
      "Loss (train): 0.9630, Acc (train): 0.8061, Loss (val): 0.5583, Acc (val): 0.8735, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 128] Epoch 2/50\n",
      "Loss (train): 0.5001, Acc (train): 0.8716, Loss (val): 0.4301, Acc (val): 0.8909, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 128] Epoch 3/50\n",
      "Loss (train): 0.4194, Acc (train): 0.8864, Loss (val): 0.3872, Acc (val): 0.8945, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 128] Epoch 4/50\n",
      "Loss (train): 0.3856, Acc (train): 0.8916, Loss (val): 0.3555, Acc (val): 0.9024, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 128] Epoch 5/50\n",
      "Loss (train): 0.3647, Acc (train): 0.8961, Loss (val): 0.3432, Acc (val): 0.9045, Epoch completed in 6.22 seconds.\n",
      "[Batch size: 128] Epoch 6/50\n",
      "Loss (train): 0.3506, Acc (train): 0.8982, Loss (val): 0.3276, Acc (val): 0.9058, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 128] Epoch 7/50\n",
      "Loss (train): 0.3394, Acc (train): 0.9015, Loss (val): 0.3198, Acc (val): 0.9087, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 128] Epoch 8/50\n",
      "Loss (train): 0.3311, Acc (train): 0.9036, Loss (val): 0.3130, Acc (val): 0.9084, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 128] Epoch 9/50\n",
      "Loss (train): 0.3225, Acc (train): 0.9049, Loss (val): 0.3103, Acc (val): 0.9124, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 128] Epoch 10/50\n",
      "Loss (train): 0.3174, Acc (train): 0.9067, Loss (val): 0.3007, Acc (val): 0.9134, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 128] Epoch 11/50\n",
      "Loss (train): 0.3147, Acc (train): 0.9076, Loss (val): 0.2981, Acc (val): 0.9133, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 128] Epoch 12/50\n",
      "Loss (train): 0.3078, Acc (train): 0.9093, Loss (val): 0.2927, Acc (val): 0.9161, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 128] Epoch 13/50\n",
      "Loss (train): 0.3014, Acc (train): 0.9116, Loss (val): 0.2933, Acc (val): 0.9131, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 128] Epoch 14/50\n",
      "Loss (train): 0.3004, Acc (train): 0.9124, Loss (val): 0.2887, Acc (val): 0.9190, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 128] Epoch 15/50\n",
      "Loss (train): 0.2951, Acc (train): 0.9138, Loss (val): 0.2860, Acc (val): 0.9180, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 128] Epoch 16/50\n",
      "Loss (train): 0.2949, Acc (train): 0.9138, Loss (val): 0.2826, Acc (val): 0.9179, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 128] Epoch 17/50\n",
      "Loss (train): 0.2932, Acc (train): 0.9131, Loss (val): 0.2839, Acc (val): 0.9166, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 128] Epoch 18/50\n",
      "Loss (train): 0.2889, Acc (train): 0.9148, Loss (val): 0.2795, Acc (val): 0.9200, Epoch completed in 6.07 seconds.\n",
      "[Batch size: 128] Epoch 19/50\n",
      "Loss (train): 0.2847, Acc (train): 0.9156, Loss (val): 0.2766, Acc (val): 0.9215, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 128] Epoch 20/50\n",
      "Loss (train): 0.2810, Acc (train): 0.9177, Loss (val): 0.2755, Acc (val): 0.9206, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 128] Epoch 21/50\n",
      "Loss (train): 0.2806, Acc (train): 0.9169, Loss (val): 0.2773, Acc (val): 0.9220, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 128] Epoch 22/50\n",
      "Loss (train): 0.2789, Acc (train): 0.9177, Loss (val): 0.2726, Acc (val): 0.9207, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 128] Epoch 23/50\n",
      "Loss (train): 0.2767, Acc (train): 0.9189, Loss (val): 0.2701, Acc (val): 0.9224, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 128] Epoch 24/50\n",
      "Loss (train): 0.2735, Acc (train): 0.9191, Loss (val): 0.2680, Acc (val): 0.9213, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 128] Epoch 25/50\n",
      "Loss (train): 0.2739, Acc (train): 0.9200, Loss (val): 0.2691, Acc (val): 0.9234, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 128] Epoch 26/50\n",
      "Loss (train): 0.2725, Acc (train): 0.9191, Loss (val): 0.2617, Acc (val): 0.9226, Epoch completed in 6.03 seconds.\n",
      "[Batch size: 128] Epoch 27/50\n",
      "Loss (train): 0.2694, Acc (train): 0.9213, Loss (val): 0.2689, Acc (val): 0.9218, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 128] Epoch 28/50\n",
      "Loss (train): 0.2677, Acc (train): 0.9221, Loss (val): 0.2637, Acc (val): 0.9243, Epoch completed in 6.24 seconds.\n",
      "[Batch size: 128] Epoch 29/50\n",
      "Loss (train): 0.2653, Acc (train): 0.9223, Loss (val): 0.2630, Acc (val): 0.9237, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 128] Epoch 30/50\n",
      "Loss (train): 0.2655, Acc (train): 0.9221, Loss (val): 0.2612, Acc (val): 0.9231, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 128] Epoch 31/50\n",
      "Loss (train): 0.2650, Acc (train): 0.9219, Loss (val): 0.2588, Acc (val): 0.9260, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 128] Epoch 32/50\n",
      "Loss (train): 0.2637, Acc (train): 0.9215, Loss (val): 0.2623, Acc (val): 0.9257, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 128] Epoch 33/50\n",
      "Loss (train): 0.2591, Acc (train): 0.9239, Loss (val): 0.2599, Acc (val): 0.9236, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 128] Epoch 34/50\n",
      "Loss (train): 0.2603, Acc (train): 0.9231, Loss (val): 0.2573, Acc (val): 0.9269, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 128] Epoch 35/50\n",
      "Loss (train): 0.2574, Acc (train): 0.9249, Loss (val): 0.2569, Acc (val): 0.9265, Epoch completed in 6.24 seconds.\n",
      "[Batch size: 128] Epoch 36/50\n",
      "Loss (train): 0.2578, Acc (train): 0.9231, Loss (val): 0.2554, Acc (val): 0.9247, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 128] Epoch 37/50\n",
      "Loss (train): 0.2561, Acc (train): 0.9247, Loss (val): 0.2552, Acc (val): 0.9246, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 128] Epoch 38/50\n",
      "Loss (train): 0.2562, Acc (train): 0.9258, Loss (val): 0.2514, Acc (val): 0.9248, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 128] Epoch 39/50\n",
      "Loss (train): 0.2532, Acc (train): 0.9248, Loss (val): 0.2571, Acc (val): 0.9252, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 128] Epoch 40/50\n",
      "Loss (train): 0.2555, Acc (train): 0.9259, Loss (val): 0.2517, Acc (val): 0.9262, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 128] Epoch 41/50\n",
      "Loss (train): 0.2535, Acc (train): 0.9260, Loss (val): 0.2520, Acc (val): 0.9273, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 128] Epoch 42/50\n",
      "Loss (train): 0.2519, Acc (train): 0.9254, Loss (val): 0.2545, Acc (val): 0.9304, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 128] Epoch 43/50\n",
      "Loss (train): 0.2513, Acc (train): 0.9266, Loss (val): 0.2486, Acc (val): 0.9279, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 128] Epoch 44/50\n",
      "Loss (train): 0.2500, Acc (train): 0.9270, Loss (val): 0.2533, Acc (val): 0.9286, Epoch completed in 6.26 seconds.\n",
      "[Batch size: 128] Epoch 45/50\n",
      "Loss (train): 0.2492, Acc (train): 0.9256, Loss (val): 0.2530, Acc (val): 0.9269, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 128] Epoch 46/50\n",
      "Loss (train): 0.2480, Acc (train): 0.9267, Loss (val): 0.2464, Acc (val): 0.9268, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 128] Epoch 47/50\n",
      "Loss (train): 0.2459, Acc (train): 0.9281, Loss (val): 0.2461, Acc (val): 0.9278, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 128] Epoch 48/50\n",
      "Loss (train): 0.2462, Acc (train): 0.9267, Loss (val): 0.2469, Acc (val): 0.9292, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 128] Epoch 49/50\n",
      "Loss (train): 0.2447, Acc (train): 0.9283, Loss (val): 0.2473, Acc (val): 0.9283, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 128] Epoch 50/50\n",
      "Loss (train): 0.2461, Acc (train): 0.9274, Loss (val): 0.2455, Acc (val): 0.9290, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 128] Training completed in 306.80 seconds.\n",
      "Wyniki zapisane do [128]custom_cnn_results.json\n",
      "[256] Loading data...\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/train\\cached_data_cupy.npz\n",
      "Loading cached dataset from D:/studia/SieciNeuronowe/dataset/test\\cached_data_cupy.npz\n",
      "Data loaded successfully.\n",
      "[Batch size: 256] Epoch 1/50\n",
      "Loss (train): 1.2441, Acc (train): 0.7994, Loss (val): 0.7414, Acc (val): 0.8688, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 256] Epoch 2/50\n",
      "Loss (train): 0.6216, Acc (train): 0.8695, Loss (val): 0.5150, Acc (val): 0.8877, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 256] Epoch 3/50\n",
      "Loss (train): 0.4817, Acc (train): 0.8873, Loss (val): 0.4278, Acc (val): 0.9000, Epoch completed in 6.28 seconds.\n",
      "[Batch size: 256] Epoch 4/50\n",
      "Loss (train): 0.4152, Acc (train): 0.8953, Loss (val): 0.3799, Acc (val): 0.9074, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 256] Epoch 5/50\n",
      "Loss (train): 0.3745, Acc (train): 0.9033, Loss (val): 0.3484, Acc (val): 0.9114, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 256] Epoch 6/50\n",
      "Loss (train): 0.3497, Acc (train): 0.9062, Loss (val): 0.3252, Acc (val): 0.9168, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 256] Epoch 7/50\n",
      "Loss (train): 0.3287, Acc (train): 0.9119, Loss (val): 0.3079, Acc (val): 0.9187, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 256] Epoch 8/50\n",
      "Loss (train): 0.3137, Acc (train): 0.9141, Loss (val): 0.2988, Acc (val): 0.9200, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 256] Epoch 9/50\n",
      "Loss (train): 0.3013, Acc (train): 0.9167, Loss (val): 0.2850, Acc (val): 0.9271, Epoch completed in 6.29 seconds.\n",
      "[Batch size: 256] Epoch 10/50\n",
      "Loss (train): 0.2903, Acc (train): 0.9204, Loss (val): 0.2764, Acc (val): 0.9252, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 256] Epoch 11/50\n",
      "Loss (train): 0.2808, Acc (train): 0.9214, Loss (val): 0.2656, Acc (val): 0.9294, Epoch completed in 6.21 seconds.\n",
      "[Batch size: 256] Epoch 12/50\n",
      "Loss (train): 0.2723, Acc (train): 0.9233, Loss (val): 0.2595, Acc (val): 0.9304, Epoch completed in 6.11 seconds.\n",
      "[Batch size: 256] Epoch 13/50\n",
      "Loss (train): 0.2649, Acc (train): 0.9258, Loss (val): 0.2553, Acc (val): 0.9302, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 256] Epoch 14/50\n",
      "Loss (train): 0.2602, Acc (train): 0.9266, Loss (val): 0.2517, Acc (val): 0.9327, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 256] Epoch 15/50\n",
      "Loss (train): 0.2553, Acc (train): 0.9276, Loss (val): 0.2419, Acc (val): 0.9337, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 256] Epoch 16/50\n",
      "Loss (train): 0.2495, Acc (train): 0.9293, Loss (val): 0.2447, Acc (val): 0.9335, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 256] Epoch 17/50\n",
      "Loss (train): 0.2451, Acc (train): 0.9304, Loss (val): 0.2360, Acc (val): 0.9365, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 256] Epoch 18/50\n",
      "Loss (train): 0.2410, Acc (train): 0.9330, Loss (val): 0.2327, Acc (val): 0.9376, Epoch completed in 6.26 seconds.\n",
      "[Batch size: 256] Epoch 19/50\n",
      "Loss (train): 0.2370, Acc (train): 0.9329, Loss (val): 0.2328, Acc (val): 0.9359, Epoch completed in 6.35 seconds.\n",
      "[Batch size: 256] Epoch 20/50\n",
      "Loss (train): 0.2337, Acc (train): 0.9335, Loss (val): 0.2241, Acc (val): 0.9389, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 256] Epoch 21/50\n",
      "Loss (train): 0.2310, Acc (train): 0.9336, Loss (val): 0.2236, Acc (val): 0.9386, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 256] Epoch 22/50\n",
      "Loss (train): 0.2270, Acc (train): 0.9362, Loss (val): 0.2212, Acc (val): 0.9395, Epoch completed in 6.05 seconds.\n",
      "[Batch size: 256] Epoch 23/50\n",
      "Loss (train): 0.2239, Acc (train): 0.9361, Loss (val): 0.2179, Acc (val): 0.9384, Epoch completed in 6.09 seconds.\n",
      "[Batch size: 256] Epoch 24/50\n",
      "Loss (train): 0.2217, Acc (train): 0.9375, Loss (val): 0.2093, Acc (val): 0.9433, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 256] Epoch 25/50\n",
      "Loss (train): 0.2193, Acc (train): 0.9379, Loss (val): 0.2159, Acc (val): 0.9402, Epoch completed in 6.08 seconds.\n",
      "[Batch size: 256] Epoch 26/50\n",
      "Loss (train): 0.2164, Acc (train): 0.9387, Loss (val): 0.2101, Acc (val): 0.9424, Epoch completed in 6.06 seconds.\n",
      "[Batch size: 256] Epoch 27/50\n",
      "Loss (train): 0.2150, Acc (train): 0.9399, Loss (val): 0.2094, Acc (val): 0.9425, Epoch completed in 6.16 seconds.\n",
      "[Batch size: 256] Epoch 28/50\n",
      "Loss (train): 0.2118, Acc (train): 0.9395, Loss (val): 0.2062, Acc (val): 0.9423, Epoch completed in 6.25 seconds.\n",
      "[Batch size: 256] Epoch 29/50\n",
      "Loss (train): 0.2092, Acc (train): 0.9411, Loss (val): 0.2070, Acc (val): 0.9425, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 256] Epoch 30/50\n",
      "Loss (train): 0.2075, Acc (train): 0.9406, Loss (val): 0.2060, Acc (val): 0.9434, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 256] Epoch 31/50\n",
      "Loss (train): 0.2048, Acc (train): 0.9419, Loss (val): 0.2009, Acc (val): 0.9451, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 256] Epoch 32/50\n",
      "Loss (train): 0.2043, Acc (train): 0.9411, Loss (val): 0.1969, Acc (val): 0.9455, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 256] Epoch 33/50\n",
      "Loss (train): 0.2029, Acc (train): 0.9422, Loss (val): 0.1967, Acc (val): 0.9471, Epoch completed in 6.23 seconds.\n",
      "[Batch size: 256] Epoch 34/50\n",
      "Loss (train): 0.2002, Acc (train): 0.9428, Loss (val): 0.2018, Acc (val): 0.9434, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 256] Epoch 35/50\n",
      "Loss (train): 0.1979, Acc (train): 0.9432, Loss (val): 0.1996, Acc (val): 0.9462, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 256] Epoch 36/50\n",
      "Loss (train): 0.1971, Acc (train): 0.9438, Loss (val): 0.1986, Acc (val): 0.9447, Epoch completed in 6.12 seconds.\n",
      "[Batch size: 256] Epoch 37/50\n",
      "Loss (train): 0.1966, Acc (train): 0.9445, Loss (val): 0.1955, Acc (val): 0.9451, Epoch completed in 6.17 seconds.\n",
      "[Batch size: 256] Epoch 38/50\n",
      "Loss (train): 0.1957, Acc (train): 0.9440, Loss (val): 0.1926, Acc (val): 0.9479, Epoch completed in 6.32 seconds.\n",
      "[Batch size: 256] Epoch 39/50\n",
      "Loss (train): 0.1928, Acc (train): 0.9444, Loss (val): 0.1932, Acc (val): 0.9455, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 256] Epoch 40/50\n",
      "Loss (train): 0.1924, Acc (train): 0.9450, Loss (val): 0.1943, Acc (val): 0.9450, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 256] Epoch 41/50\n",
      "Loss (train): 0.1914, Acc (train): 0.9448, Loss (val): 0.1925, Acc (val): 0.9468, Epoch completed in 6.19 seconds.\n",
      "[Batch size: 256] Epoch 42/50\n",
      "Loss (train): 0.1888, Acc (train): 0.9455, Loss (val): 0.1882, Acc (val): 0.9473, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 256] Epoch 43/50\n",
      "Loss (train): 0.1889, Acc (train): 0.9466, Loss (val): 0.1868, Acc (val): 0.9480, Epoch completed in 6.18 seconds.\n",
      "[Batch size: 256] Epoch 44/50\n",
      "Loss (train): 0.1874, Acc (train): 0.9457, Loss (val): 0.1858, Acc (val): 0.9467, Epoch completed in 6.13 seconds.\n",
      "[Batch size: 256] Epoch 45/50\n",
      "Loss (train): 0.1869, Acc (train): 0.9463, Loss (val): 0.1901, Acc (val): 0.9454, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 256] Epoch 46/50\n",
      "Loss (train): 0.1841, Acc (train): 0.9469, Loss (val): 0.1871, Acc (val): 0.9464, Epoch completed in 6.10 seconds.\n",
      "[Batch size: 256] Epoch 47/50\n",
      "Loss (train): 0.1843, Acc (train): 0.9469, Loss (val): 0.1826, Acc (val): 0.9479, Epoch completed in 6.31 seconds.\n",
      "[Batch size: 256] Epoch 48/50\n",
      "Loss (train): 0.1830, Acc (train): 0.9473, Loss (val): 0.1833, Acc (val): 0.9483, Epoch completed in 6.14 seconds.\n",
      "[Batch size: 256] Epoch 49/50\n",
      "Loss (train): 0.1834, Acc (train): 0.9475, Loss (val): 0.1839, Acc (val): 0.9482, Epoch completed in 6.15 seconds.\n",
      "[Batch size: 256] Epoch 50/50\n",
      "Loss (train): 0.1799, Acc (train): 0.9484, Loss (val): 0.1824, Acc (val): 0.9490, Epoch completed in 6.20 seconds.\n",
      "[Batch size: 256] Training completed in 308.51 seconds.\n",
      "Wyniki zapisane do [256]custom_cnn_results.json\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    # load data\n",
    "    print(f\"[{batch_size}] Loading data...\")\n",
    "    train_loader = Data(\n",
    "        path=\"D:/studia/SieciNeuronowe/dataset/train\", batch_size=64, use_cupy=True\n",
    "    )\n",
    "    val_loader = Data(\n",
    "        path=\"D:/studia/SieciNeuronowe/dataset/test\", batch_size=64, use_cupy=True\n",
    "    )\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # MODEL\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(\n",
    "                input_channels=1, output_channels=8, kernel_size=2, stride=1, padding=1\n",
    "            ),\n",
    "            ReLU(),\n",
    "            MaxPool2D(kernel_size=2, stride=2),\n",
    "            Dropout(0.3),  # Dropout layer with 40% dropout rate\n",
    "            Flatten(),\n",
    "            Dense(input_size=8 * 14 * 14, output_size=10),\n",
    "        ]\n",
    "    )\n",
    "    loss_fn = SoftmaxCrossEntropyLoss()\n",
    "    optimizer = AdamOptimizer(learning_rate=0.005)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    epochs_done_all = {}\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    epochs_done = 0\n",
    "    num_epochs = 50\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"[Batch size: {batch_size}] Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            logits = model.forward(x_batch)\n",
    "            loss = loss_fn.forward(logits, y_batch)\n",
    "            grad = loss_fn.backward()\n",
    "            model.backward(grad)\n",
    "            model.update(optimizer)\n",
    "\n",
    "            train_loss += float(loss)\n",
    "            train_acc += float(compute_accuracy(logits, y_batch))\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss /= num_batches\n",
    "        train_acc /= num_batches\n",
    "\n",
    "        val_logits = model.forward(val_loader.X)\n",
    "        val_loss = loss_fn.forward(val_logits, val_loader.y)\n",
    "        val_acc = compute_accuracy(val_logits, val_loader.y)\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "        print(\n",
    "            f\"Loss (train): {train_loss:.4f}, Acc (train): {train_acc:.4f}, \"\n",
    "            f\"Loss (val): {float(val_loss):.4f}, Acc (val): {float(val_acc):.4f}, \"\n",
    "            f\"Epoch completed in {time.time() - epoch_start_time:.2f} seconds.\"\n",
    "        )\n",
    "        epochs_done += 1\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(float(val_loss))\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(float(val_acc))\n",
    "    print(\n",
    "        f\"[Batch size: {batch_size}] Training completed in {time.time() - start_time:.2f} seconds.\"\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    epochs_done_all[batch_size] = epochs_done\n",
    "    training_times[batch_size] = training_time\n",
    "    all_train_losses[batch_size] = train_losses\n",
    "    all_val_losses[batch_size] = val_losses\n",
    "    all_train_accuracies[batch_size] = train_accuracies\n",
    "    all_val_accuracies[batch_size] = val_accuracies\n",
    "    true_labels = val_loader.y.get()\n",
    "    val_logits = model.forward(val_loader.X)\n",
    "    val_preds = np.argmax(val_logits.get(), axis=1)\n",
    "\n",
    "    cm = confusion_matrix(true_labels, val_preds)\n",
    "    confusion_matrices[batch_size] = cm\n",
    "    results = {\n",
    "        \"train_loss\": train_losses,\n",
    "        \n",
    "        \"val_loss\": val_losses,\n",
    "        \"train_accuracy\": train_accuracies,\n",
    "        \"val_accuracy\": val_accuracies,\n",
    "        \"training_time_seconds\": training_time,\n",
    "        \"confusion_matrix\": cm.tolist(),  # Convert to list for JSON serialization\n",
    "        \"epochs_done\": epochs_done,\n",
    "    }\n",
    "\n",
    "    # Save results to JSON file\n",
    "    with open(f\"../DOCS/[{batch_size}]custom_cnn_results.json\", \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    print(f\"Wyniki zapisane do [{batch_size}]custom_cnn_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
